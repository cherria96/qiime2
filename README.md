# qiime2
NGS data analysis using qiime2
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[Pipeline manual]
1. activate qiime2 environment
command : conda activate qiime2 

2. Create a folder name 'fastq'. Under this directory, create folders and files like below.

fastq
 ㄴARC (folder)
	ㄴARC fastq.gz (fastq files)
 ㄴBAC (folder)
	ㄴBAC fastq.gz (fastq files)
 ㄴsample-metadata-arc.tsv (Refer to [Metadata file] to create)
 ㄴsample-metadata-bac.tsv

3. You will see two folders overall 
1) fastq	2) qiime2 (provided)

4. Go to qiime2 directory

5. execute qiime2_cmd.sh
command : ./qiime2_cmd.sh
 - this returns trimmed sequences, denoised&merged sequences, some statistics (seq length, feature frequency ..etc) files
 - Input 1: which domain of sequences to get, chosen either from BAC or ARC (You'll know what this is abt after executing qiime2_cmd.sh)

6. Go to 'https://view.qiime2.org/'. From the output files from procedure 4, put 'dada2_table.qzv' as the input file.
 - get the info of frequency per sample from 'Overview'
 - get the info of minimum feature count from 'Interactive Sample Detail'

7. execute qiime2_analysis.sh
command : ./qiime2_analysis.sh
 - this returns silva taxonomy matched files, diversity analysis results.
 - Input 1: which domain to get 
 - Input 2: frequency per sample (from procedure 5)
 - Input 3 (sampling depth): minimum feature count (from procedure 5)
 - Input 4: any categorical column from metadata file you want to categorize data (used in weighted unifrac distance matrix)

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[Metadata file : sample-metadata-arc.tsv, sample-metadata-bac.tsv]
This is the information you want to provide for each sample. It can be anything such as 'experiment', 'elapsed days', 'substrate' .. etc.
Only thing required (mandatory) is the first column named with 'sampleid' and should contain the sample name. 
The sample name should be in this pattern :
For example, if the name of fastq file is 'CJU-0d-ARC_S65_L001_R1_001.fastq', 
the sampleid should be 'CJU-0d-ARC'
'S65' refers to barcode sequence, 'L001' to lane number, 'R1' to the direction of the read, '001' to the set number. 

After creating 'sampleid' column, you can add any columns but with the 'tab' separtaion as you can see from the file extension 'tsv'.
For example,
sampleid	time	experiment
PBAT2-end-ARC	end	PBAT2
PBAT2-mid-ARC	mid	PBAT2

If it is too burden for creating metadata file, run create-metadata.py.
command : python create-metadata.py
It will create arc, bac metadata files each but adding descriptions should be manually done. 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[taxanomy organizing]
When you want get read abundance file with separate hierarchy, use 'taxa_organizer.py'

1. Go to 'https://view.qiime2.org/'. Put 'silva_16S_barplot.qzv' as the input file.

2. Set the Taxonomic Level with Level 7 and download the CSV

3. run taxa_organizer.py
command : python taxa_organizer.py
 - Input 1: CSV file downloaded from procedure 2
 - Input 2: Metadata file
 - Input 3: file name.xlsx 
 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[NCBI matching]
1. Go to 'https://view.qiime2.org/'. Put 'dada2_rep_seqs.qzv' as the input file.

2. Download sequences as a raw FASTA file

3. Go to 'NCBI nucleotide blast' website and upload the downloaded file.
 - Database rRNA/ITS : 16S rRNA sequences (Bacteria and Archaea)
 - In archaea case, exclude eukaryotes in organism 
 - Optimize for somewhat similar sequences (blastn)

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[Others (FYI)]
*About qiime files
In qiime, we get files with extension of either qza or qzv. qzv files are simply the visualization of qza files. 
In order to visualize qzv files, go to 'https://view.qiime2.org/' and drag the files there. 

*Silva database
The pipeline is currently using SILVA_DB_138_99. It can be updated and modified. Let everyone knows, if silva database had been or needed to be updated.
With new database, it should be re-trained with naiive-bayers classifier which can be done by executing qiime2_NBclf.sh.
This takes a lot of time and memory, so be prepared.

*Initial setting
Those who wants to create qiime2 environment on personal computer, you can run qiime2_setting.sh. 
However, before running qiime2_setting.sh, conda should be installed on your computer.
This computer uses 2022.10 version of anaconda.

